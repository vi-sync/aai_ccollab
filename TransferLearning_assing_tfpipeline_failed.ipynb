{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_assing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNxjo8dGANSEhASdLkUn0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vi-sync/aai_ccollab/blob/main/TransferLearning_assing_tfpipeline_failed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget wget --header=\"Host: doc-10-8k-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://drive.google.com/\" --header=\"Cookie: AUTH_m6rfddh0fqtjuddbh79vvq5hkvpnqdek_nonce=mq2ligik93t5e\" --header=\"Connection: keep-alive\" \"https://doc-10-8k-docs.googleusercontent.com/docs/securesc/9j6sm21ntfm0afitj8tvf4lb1e6akhi6/0s5qskl52udq0nrc907nviakhurthrqi/1652082525000/00484516897554883881/01056278689497542515/1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu?e=download&ax=ACxEAsYSk8_rF7umK0ovZEiPJvMNo183Tg19z0lAbI4pcvgMFFRcJ2NX3VPnQV20qb7MTPE68LSviXAS2TiKwe04ddu_Zv5HO2sXWMidr5_dElonaIUd0IJr_F63uh4kW2dBj22dtckJRIdxYUCaJ7LtNx0PYS-giyD6X_v7h6Y9Pd1H9JWU2hrkX29Yujw1aHKa0L-VVx89JCBT6ZDtk0vdquHWDM-qGGKk7llwoVwPYelfvwUt934Avl_1Bdhos8vrNWOpHS1Hph3R-ZE_hycBWGEQp8ryqb7AFJy7mEsLWfluG-fgpWuARqOV8QV0oEx620kRGcS2YvE4HTQsVAHWo9FW_FEZusVFccKocW333mP6P-hiJV5YPVkFSqCwxHhYpwaGrm1EawtSp-U-k3QSOlP5V2T33yWux-l9YTAAz0xnkiXMX22oUlTL0wEBYSI1_hsaMAEndSBvrG3sQ1Uvc8OxSWsDn3-AX9n2cAR78dun9X4Xu2yg7lvzS9pIlXgkaYTEvC3fDnAf_ybosm2qorLKjy0bYpJ7Ro-FcViNBL1VgBCJaprpB7GUTSRBPoKhvPVTbDBUgY5nG-pbleysnijgERd57CHQVsOOkieKdTawusnd6Kv283NT3XziNGl-X0lA7csm60E7eHUkeDsW53VLaVH8AcUfgbatczwla7ocjvTAI4z6LUicRSfr1HDesV79mnJgY0O5Mq5kNHTxcwhbNMq5kZJO8zjaRs9b&authuser=0&nonce=mq2ligik93t5e&user=01056278689497542515&hash=l4ln1d9bkpnfns2d1b7f4gqp7nihgaup\" -c -O 'rvl-cdip.rar'"
      ],
      "metadata": {
        "id": "uUBREPTFMyy5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q git+https://github.com/tensorflow/examples.git"
      ],
      "metadata": {
        "id": "TXr1_b-Gk8U7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow-io"
      ],
      "metadata": {
        "id": "5SVWvFahSt3g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow\n",
        "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rn\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "import math\n",
        "\n",
        "#from tensorflow.io.experimental.image import decode_tiff\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "O-ZdKiJULQeb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "TpAIDdeB5ili"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unrar x /content/rvl-cdip.rar "
      ],
      "metadata": {
        "id": "_rAHIqoyLdAd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pathlib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "\n",
        "from time import time\n",
        "import tensorflow_io as tfio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NnkgNprYLg4X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3jtyhO4XSsV1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/labels_final.csv\")"
      ],
      "metadata": {
        "id": "6MaYgGk2MIPD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VO9BmdlGRQWZ",
        "outputId": "e7058084-f0ea-4fbe-b296-effa87206640"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             path  label\n",
              "0      imagesv/v/o/h/voh71d00/509132755+-2755.tif      3\n",
              "1            imagesl/l/x/t/lxt19d00/502213303.tif      3\n",
              "2           imagesx/x/e/d/xed05a00/2075325674.tif      2\n",
              "3      imageso/o/j/b/ojb60d00/517511301+-1301.tif      3\n",
              "4           imagesq/q/z/k/qzk17e00/2031320195.tif      7\n",
              "...                                           ...    ...\n",
              "47995      imagesk/k/q/l/kql82f00/tob07414.87.tif     10\n",
              "47996  imagesi/i/r/r/irr80c00/2084343690_3692.tif     12\n",
              "47997  imagesa/a/z/h/azh32d00/2063887153_7176.tif      6\n",
              "47998       imagesg/g/p/d/gpd45f00/0060075263.tif      8\n",
              "47999       imagesr/r/o/l/rol45d00/2064701657.tif      1\n",
              "\n",
              "[48000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5f22bca-4332-4cbd-9220-d5777a91575e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47995</th>\n",
              "      <td>imagesk/k/q/l/kql82f00/tob07414.87.tif</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47996</th>\n",
              "      <td>imagesi/i/r/r/irr80c00/2084343690_3692.tif</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47997</th>\n",
              "      <td>imagesa/a/z/h/azh32d00/2063887153_7176.tif</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47998</th>\n",
              "      <td>imagesg/g/p/d/gpd45f00/0060075263.tif</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47999</th>\n",
              "      <td>imagesr/r/o/l/rol45d00/2064701657.tif</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5f22bca-4332-4cbd-9220-d5777a91575e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5f22bca-4332-4cbd-9220-d5777a91575e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5f22bca-4332-4cbd-9220-d5777a91575e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/data_final\""
      ],
      "metadata": {
        "id": "gj9ipxnuRRG7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(pathlib.Path(path).iterdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X6_3ttJRWkt",
        "outputId": "828e9b10-c5e6-4ab7-9ca2-0d7c526960ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/data_final/imagesw'),\n",
              " PosixPath('/content/data_final/imagesp'),\n",
              " PosixPath('/content/data_final/imagese'),\n",
              " PosixPath('/content/data_final/imagesz'),\n",
              " PosixPath('/content/data_final/imagesu'),\n",
              " PosixPath('/content/data_final/imageso'),\n",
              " PosixPath('/content/data_final/imagesc'),\n",
              " PosixPath('/content/data_final/imagesx'),\n",
              " PosixPath('/content/data_final/imagesv'),\n",
              " PosixPath('/content/data_final/imagesl'),\n",
              " PosixPath('/content/data_final/imagesn'),\n",
              " PosixPath('/content/data_final/imagesm'),\n",
              " PosixPath('/content/data_final/imagesd'),\n",
              " PosixPath('/content/data_final/imagesr'),\n",
              " PosixPath('/content/data_final/imagesi'),\n",
              " PosixPath('/content/data_final/imagest'),\n",
              " PosixPath('/content/data_final/imagesh'),\n",
              " PosixPath('/content/data_final/imagesk'),\n",
              " PosixPath('/content/data_final/imagesy'),\n",
              " PosixPath('/content/data_final/imagesf'),\n",
              " PosixPath('/content/data_final/imagesj'),\n",
              " PosixPath('/content/data_final/imagesg'),\n",
              " PosixPath('/content/data_final/imagesq'),\n",
              " PosixPath('/content/data_final/imagesb'),\n",
              " PosixPath('/content/data_final/imagesa')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.path[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4ooGIGYzRa2K",
        "outputId": "b9bb4e9d-88e7-4bd3-d883-54b9f986598a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'imagesl/l/x/t/lxt19d00/502213303.tif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "str(pathlib.Path(df.path[1]))\n",
        "int(df.label[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe-xwgBjRqHE",
        "outputId": "d03f8c79-a115-4e42-e5c3-8d6711ffcc50"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#adding 'content\\data_fianl in frot of the image paths"
      ],
      "metadata": {
        "id": "ug0p3rdpigva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['path_full']=df['path'].apply(lambda x : '/content/data_final/' + x )"
      ],
      "metadata": {
        "id": "dHiLO7bERwhH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "9Dt5__dIR5Qy",
        "outputId": "95960630-7824-4771-9137-64132787c68f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             path  label  \\\n",
              "0      imagesv/v/o/h/voh71d00/509132755+-2755.tif      3   \n",
              "1            imagesl/l/x/t/lxt19d00/502213303.tif      3   \n",
              "2           imagesx/x/e/d/xed05a00/2075325674.tif      2   \n",
              "3      imageso/o/j/b/ojb60d00/517511301+-1301.tif      3   \n",
              "4           imagesq/q/z/k/qzk17e00/2031320195.tif      7   \n",
              "...                                           ...    ...   \n",
              "47995      imagesk/k/q/l/kql82f00/tob07414.87.tif     10   \n",
              "47996  imagesi/i/r/r/irr80c00/2084343690_3692.tif     12   \n",
              "47997  imagesa/a/z/h/azh32d00/2063887153_7176.tif      6   \n",
              "47998       imagesg/g/p/d/gpd45f00/0060075263.tif      8   \n",
              "47999       imagesr/r/o/l/rol45d00/2064701657.tif      1   \n",
              "\n",
              "                                               path_full  \n",
              "0      /content/data_final/imagesv/v/o/h/voh71d00/509...  \n",
              "1      /content/data_final/imagesl/l/x/t/lxt19d00/502...  \n",
              "2      /content/data_final/imagesx/x/e/d/xed05a00/207...  \n",
              "3      /content/data_final/imageso/o/j/b/ojb60d00/517...  \n",
              "4      /content/data_final/imagesq/q/z/k/qzk17e00/203...  \n",
              "...                                                  ...  \n",
              "47995  /content/data_final/imagesk/k/q/l/kql82f00/tob...  \n",
              "47996  /content/data_final/imagesi/i/r/r/irr80c00/208...  \n",
              "47997  /content/data_final/imagesa/a/z/h/azh32d00/206...  \n",
              "47998  /content/data_final/imagesg/g/p/d/gpd45f00/006...  \n",
              "47999  /content/data_final/imagesr/r/o/l/rol45d00/206...  \n",
              "\n",
              "[48000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42f42bcb-fa70-4ca6-b6af-8c97c5d62a62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>path_full</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/data_final/imagesv/v/o/h/voh71d00/509...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/data_final/imagesl/l/x/t/lxt19d00/502...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/data_final/imagesx/x/e/d/xed05a00/207...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/data_final/imageso/o/j/b/ojb60d00/517...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
              "      <td>7</td>\n",
              "      <td>/content/data_final/imagesq/q/z/k/qzk17e00/203...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47995</th>\n",
              "      <td>imagesk/k/q/l/kql82f00/tob07414.87.tif</td>\n",
              "      <td>10</td>\n",
              "      <td>/content/data_final/imagesk/k/q/l/kql82f00/tob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47996</th>\n",
              "      <td>imagesi/i/r/r/irr80c00/2084343690_3692.tif</td>\n",
              "      <td>12</td>\n",
              "      <td>/content/data_final/imagesi/i/r/r/irr80c00/208...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47997</th>\n",
              "      <td>imagesa/a/z/h/azh32d00/2063887153_7176.tif</td>\n",
              "      <td>6</td>\n",
              "      <td>/content/data_final/imagesa/a/z/h/azh32d00/206...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47998</th>\n",
              "      <td>imagesg/g/p/d/gpd45f00/0060075263.tif</td>\n",
              "      <td>8</td>\n",
              "      <td>/content/data_final/imagesg/g/p/d/gpd45f00/006...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47999</th>\n",
              "      <td>imagesr/r/o/l/rol45d00/2064701657.tif</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/data_final/imagesr/r/o/l/rol45d00/206...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42f42bcb-fa70-4ca6-b6af-8c97c5d62a62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42f42bcb-fa70-4ca6-b6af-8c97c5d62a62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42f42bcb-fa70-4ca6-b6af-8c97c5d62a62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(pathlib.Path(str(df['path_full'][1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mZHf-Yv7T5ZZ",
        "outputId": "8c59e2dc-a4ac-419c-d309-0b34ade80469"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data_final/imagesl/l/x/t/lxt19d00/502213303.tif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ISFArPtTTnyK",
        "outputId": "fc40005e-3244-4365-c658-36afc2975c8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data_final'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_image_path=df['path_full'].values\n",
        "all_image_path[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rq2Kea09OmT9",
        "outputId": "7f3c0a79-8296-4e47-b48c-debdcfe1989b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data_final/imagesl/l/x/t/lxt19d00/502213303.tif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_image_label=df['label'].values\n",
        "all_image_label[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_3O-hqaO0tD",
        "outputId": "60d86f1f-b9e3-4922-fed7-1a7d6cbb07e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df['path_full'].values\n",
        "y=df['label'].values"
      ],
      "metadata": {
        "id": "vAnw0xZ16h0G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0yBJJ4Y6zQf",
        "outputId": "bdf33c5b-2543-4286-a6da-5581c8fa7d5b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/data_final/imagesv/v/o/h/voh71d00/509132755+-2755.tif',\n",
              "       '/content/data_final/imagesl/l/x/t/lxt19d00/502213303.tif',\n",
              "       '/content/data_final/imagesx/x/e/d/xed05a00/2075325674.tif', ...,\n",
              "       '/content/data_final/imagesa/a/z/h/azh32d00/2063887153_7176.tif',\n",
              "       '/content/data_final/imagesg/g/p/d/gpd45f00/0060075263.tif',\n",
              "       '/content/data_final/imagesr/r/o/l/rol45d00/2064701657.tif'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLJ_6QH99YQH",
        "outputId": "ae40fa06-9b7a-466a-d651-7faf9d09fa50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 2, ..., 6, 8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test split"
      ],
      "metadata": {
        "id": "0h-wlCvB53d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(all_image_path,all_image_label,stratify=all_image_label,train_size=0.7)"
      ],
      "metadata": {
        "id": "LUqj6veo52RM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *val data is actually the test data*"
      ],
      "metadata": {
        "id": "HKj4sXU47heL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wap_yUHe-KGR",
        "outputId": "86c4e91a-71ee-412d-b5cf-64791d359b02"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33600,) (33600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def tfdata_generator(images, labels, is_training, batch_size=32):\n",
        "    '''Construct a data generator using tf.Dataset'''\n",
        "    \n",
        "    def parse_function(images, label):\n",
        "        #reading path \n",
        "        image_string = tf.io.read_file(images)\n",
        "        #decoding image\n",
        "        #image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "       \n",
        "        #image=tfio.experimental.image.decode_tiff(image_string)\n",
        "        image=tfio.experimental.image.decode_tiff(image_string)\n",
        "\n",
        "        # This will convert to float values in [0, 1]\n",
        "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "        #resize the image\n",
        "        image = tf.image.resize(image, (224, 224))\n",
        "        #plt.imshow(image)\n",
        "        #one hot coding for label\n",
        "        label = tf.one_hot(tf.cast(label, tf.uint8), 8)\n",
        "        return image, label\n",
        "    \n",
        "    def flip(image,label):\n",
        "      image=tf.image.random_flip_up_down(image)\n",
        "      image=tf.image.random_flip_up_down(image)\n",
        "      return image,y\n",
        "\n",
        "    def rotate(image,label):\n",
        "      image=tf.image.rot90(image,3)\n",
        "      return image,label\n",
        "    \n",
        "    #def bright(image,label):\n",
        "      #image=tf.image.adjust_brightness(image,0.2)\n",
        "      #return image,label\n",
        "    #def contrast(image,label)\n",
        "      #image=tf.image.adjust_contrast(image,contrast_factor=0.6)\n",
        "      #return image,label\n",
        "\n",
        "    def color(image,labels):\n",
        "        image = tf.image.random_hue(image, 0.08)\n",
        "        image = tf.image.random_saturation(image, 0.6, 1.6)\n",
        "        image = tf.image.random_brightness(image, 0.05)\n",
        "        image = tf.image.random_contrast(image, 0.7, 1.3)\n",
        "        return image,labels\n",
        "\n",
        "\n",
        "    ##creating a dataset from tensorslices\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    \n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(5000)  # depends on sample size\n",
        "\n",
        "    # Transform and batch data at the same time\n",
        "    dataset = dataset.apply(tf.data.experimental.map_and_batch( parse_function, batch_size,num_parallel_batches=4,  # cpu cores\n",
        "        drop_remainder=True if is_training else False))\n",
        "    \n",
        "    augmentation=[flip,rotate,color]\n",
        "    \n",
        "    if is_training:\n",
        "      for f in augmentation:\n",
        "        if np.random.uniform(0,1)>0.6:\n",
        "          dataset=dataset.map(f,num_parallel_calls=4)\n",
        "\n",
        "    \n",
        "    #repeat the dataset indefinitely\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "    \n",
        "    #prefetch the data into CPU/GPU\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset\"\"\""
      ],
      "metadata": {
        "id": "Y0OBkw2GkntN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "4e942e18-9137-4f0e-8c9b-c548fa66428d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef tfdata_generator(images, labels, is_training, batch_size=32):\\n    '''Construct a data generator using tf.Dataset'''\\n    \\n    def parse_function(images, label):\\n        #reading path \\n        image_string = tf.io.read_file(images)\\n        #decoding image\\n        #image = tf.image.decode_jpeg(image_string, channels=3)\\n       \\n        #image=tfio.experimental.image.decode_tiff(image_string)\\n        image=tfio.experimental.image.decode_tiff(image_string)\\n\\n        # This will convert to float values in [0, 1]\\n        image = tf.image.convert_image_dtype(image, tf.float32)\\n        #resize the image\\n        image = tf.image.resize(image, (224, 224))\\n        #plt.imshow(image)\\n        #one hot coding for label\\n        label = tf.one_hot(tf.cast(label, tf.uint8), 8)\\n        return image, label\\n    \\n    def flip(image,label):\\n      image=tf.image.random_flip_up_down(image)\\n      image=tf.image.random_flip_up_down(image)\\n      return image,y\\n\\n    def rotate(image,label):\\n      image=tf.image.rot90(image,3)\\n      return image,label\\n    \\n    #def bright(image,label):\\n      #image=tf.image.adjust_brightness(image,0.2)\\n      #return image,label\\n    #def contrast(image,label)\\n      #image=tf.image.adjust_contrast(image,contrast_factor=0.6)\\n      #return image,label\\n\\n    def color(image,labels):\\n        image = tf.image.random_hue(image, 0.08)\\n        image = tf.image.random_saturation(image, 0.6, 1.6)\\n        image = tf.image.random_brightness(image, 0.05)\\n        image = tf.image.random_contrast(image, 0.7, 1.3)\\n        return image,labels\\n\\n\\n    ##creating a dataset from tensorslices\\n    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\\n    \\n    if is_training:\\n        dataset = dataset.shuffle(5000)  # depends on sample size\\n\\n    # Transform and batch data at the same time\\n    dataset = dataset.apply(tf.data.experimental.map_and_batch( parse_function, batch_size,num_parallel_batches=4,  # cpu cores\\n        drop_remainder=True if is_training else False))\\n    \\n    augmentation=[flip,rotate,color]\\n    \\n    if is_training:\\n      for f in augmentation:\\n        if np.random.uniform(0,1)>0.6:\\n          dataset=dataset.map(f,num_parallel_calls=4)\\n\\n    \\n    #repeat the dataset indefinitely\\n    dataset = dataset.repeat()\\n\\n    \\n    #prefetch the data into CPU/GPU\\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\\n\\n    return dataset\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tfdata_generator(images, labels, is_training, batch_size=32):\n",
        "    '''Construct a data generator using tf.Dataset'''\n",
        "    \n",
        "    def parse_function(images,labels):\n",
        "        #reading path \n",
        "        #image_string = tf.io.read_file(filename)\n",
        "        #decoding image\n",
        "        #image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "        filecontent = tf.io.read_file(images)\n",
        "        image = tfio.experimental.image.decode_tiff(filecontent)\n",
        "\n",
        "        # This will convert to float values in [0, 1]\n",
        "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "        \n",
        "        image = tf.image.resize(image, (224, 224))\n",
        "        \n",
        "        y = tf.one_hot(tf.cast(labels, tf.uint8), 8)\n",
        "        return image,y\n",
        "    \n",
        "    def flip(image,labels):\n",
        "        \n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "        \n",
        "        return image,labels\n",
        "    \n",
        "    def rotate(image,labels):\n",
        "\n",
        "        return tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)),labels\n",
        "    \n",
        "    def color(image,labels):\n",
        "        #image = tf.image.random_hue(image, 0.08)\n",
        "        image = tf.image.random_saturation(image, 0.6, 1.6)\n",
        "        image = tf.image.random_brightness(image, 0.05)\n",
        "        image = tf.image.random_contrast(image, 0.7, 1.3)\n",
        "        return image,labels\n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images,labels))\n",
        "    \n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(5000)  # depends on sample size\n",
        "        \n",
        "    # Transform and batch data at the same time\n",
        "    dataset = dataset.map(parse_function, num_parallel_calls=4)\n",
        "    \n",
        "    augmentations = [flip,rotate,color]\n",
        "    \n",
        "    if is_training:\n",
        "        for f in augmentations:\n",
        "            if np.random.uniform(0,1)>0.6:\n",
        "                dataset = dataset.map(f,num_parallel_calls=4)\n",
        "    \n",
        "    dataset = dataset.repeat()\n",
        "    \n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "OjGVZkCIr16J"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data_gen=tfdata_generator(x_train,y_train,is_training=True,batch_size=32)"
      ],
      "metadata": {
        "id": "mH_-2h8IvEUG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_gen=tfdata_generator(x_test,y_test,is_training=False,batch_size=32)"
      ],
      "metadata": {
        "id": "ppZ9s12CPXcT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for train data\n",
        "steps_per_epoch=np.ceil(len(x_train)/32)\n",
        "steps_per_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWLNL0xYS1To",
        "outputId": "827ce1a1-99a4-4e8e-f438-94c252c0910a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1050.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for train data\n",
        "#for test data\n",
        "import time\n",
        "start=time.time()\n",
        "l=0\n",
        "for x,y in train_data_gen.take(steps_per_epoch):\n",
        "  l+=1\n",
        "  pass\n",
        "end=time.time()\n",
        "print('time taken to load ',(end-start)/60,' minutes')\n",
        "print(l)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "WbqA0mO2TB17",
        "outputId": "68213dd6-a8c6-496e-8c6a-7bfeb67b943e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3bc3217da7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0ml\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    820\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2921\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2923\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2924\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: input must have 3 channels but instead has 4 channels.\n\t [[{{node adjust_saturation/AdjustSaturation}}]] [Op:IteratorGetNext]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_test),len(x_train))"
      ],
      "metadata": {
        "id": "QwzozrzeTF6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch_val=np.ceil(len(x_test)/32)\n",
        "steps_per_epoch_val"
      ],
      "metadata": {
        "id": "pSKn7aimS1We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for test data\n",
        "start=time.time()\n",
        "l=0\n",
        "for x,y in test_data_gen.take(steps_per_epoch_val):\n",
        "  l+=1\n",
        "  pass\n",
        "end=time.time()\n",
        "print('time taken to load ',(end-start)/60,' minutes')\n",
        "print(l)"
      ],
      "metadata": {
        "id": "Es5XTLsAS1az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building models"
      ],
      "metadata": {
        "id": "vkYNfu4MHEQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "ZaTLwkdKlh4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.activations import relu"
      ],
      "metadata": {
        "id": "6JUpXhoys1Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import Model \n"
      ],
      "metadata": {
        "id": "Q0MNuJf4ld5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow"
      ],
      "metadata": {
        "id": "wKB42n5gpWQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import vgg16 \n"
      ],
      "metadata": {
        "id": "3TNCdir1S1cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"vgg_1=VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5Y46P0lrS1gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2C9BbUNWkrsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorflow.keras.backend.clear_session()\n",
        "base_model=vgg16.VGG16(weights='imagenet',include_top=False)\n",
        "base_model.trainable=False\n",
        "input_layer=Input(shape=(224,224,4),name='input_layer')"
      ],
      "metadata": {
        "id": "O_8H_YYh2nbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=base_model(input_layer)"
      ],
      "metadata": {
        "id": "SFyrF9H_BLsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv1=Conv2D(128,(3,3),activation=relu,kernel_initializer=tf.keras.initializers.he_normal())(x)\n",
        "mp1=MaxPool2D()(conv1)\n",
        "#flattening\n",
        "flat1=Flatten()(mp1)\n",
        "#1st dense or fuly connected layer\n",
        "fc1=Dense(50,activation=relu,kernel_initializer=tf.keras.initializers.he_normal())(flat1)\n",
        "fc2=Dense(50,activation=relu,kernel_initializer=tf.keras.initializers.he_normal())(fc1)\n",
        "#output layer for 16 classes\n",
        "output_layer=Dense(16,activation=softmax)(fc2)\n",
        "\n",
        "model_1=Model(inputs=input_layer,outputs=output_layer)\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "id": "ZStdT4qU1gJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KJQuLPID-2sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optmzer=tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "CXifLDZc_eay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss='categorical_crossentropy',optimizer=optmzer,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6igjeZPQ-2vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating call backs:: "
      ],
      "metadata": {
        "id": "LgIsNZTiDG2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import callbacks\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "IYtoWTr9DaF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_decay(epoch,lr):\n",
        "  if epoch!=0 and epoch%4==0:\n",
        "    lr=lr*0.5\n",
        "  return lr \n",
        "\n",
        "lr_scheduler=callbacks.LearningRateScheduler(schedule=lr_decay)"
      ],
      "metadata": {
        "id": "PfURnOaWQ5C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name='Model_1'\n",
        "#logdir='logs/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir=os.path.join('logs',datetime.now().strftime(\"%Y%m%d=%H%M%S\"),name)\n",
        "tfboard=callbacks.TensorBoard(log_dir=logdir,histogram_freq=1)"
      ],
      "metadata": {
        "id": "ORUchHhWDaKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuduce_on_platue=callbacks.ReduceLROnPlateau()\n"
      ],
      "metadata": {
        "id": "tFrVuMrMRcUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_path = 'model_checkpoints/'\n",
        "os.mkdir=checkpoint_path\n",
        "checkpoint = callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_freq='epoch',\n",
        "    save_weights_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "3n7Wd-nEDaM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.fit_generator(train_data_gen,steps_per_epoch=1050,epochs=5,use_multiprocessing=True,\n",
        "                      callbacks=[lr_scheduler,reuduce_on_platue,checkpoint])"
      ],
      "metadata": {
        "id": "UwvzM0Hw-2xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Da5v-PUM-2z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AltjS3j3-22b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hCxWlxxG-24u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CEOETuLU-29l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=vgg_1.output"
      ],
      "metadata": {
        "id": "ajrNZPZ41AJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.activations import softmax\n"
      ],
      "metadata": {
        "id": "sOaycFbhv3zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc1=Conv2D(filters=512,kernel_size=(3,3),activation=relu)(x)\n",
        "mp1=MaxPool2D(padding='same')(fc1)\n",
        "fc2=Conv2D(filters=512,kernel_size=(3,3),activation=relu)(mp1)\n",
        "output_layer=Dense(16,softmax)(fc2)\n"
      ],
      "metadata": {
        "id": "YOCxMrt2ABtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using default shape due the error"
      ],
      "metadata": {
        "id": "NgjNNf3g8hJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_1=VGG16(weights='imagenet',include_top=False)\n",
        "for layers in vgg_1.layers:\n",
        "  layers.trainable=False"
      ],
      "metadata": {
        "id": "DMqSucNc8XF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=vgg_1.output\n",
        "fc1=Conv2D(filters=512,kernel_size=(3,3),activation=relu)(x)\n",
        "mp1=MaxPool2D(padding='same')(fc1)\n",
        "fc2=Conv2D(filters=512,kernel_size=(3,3),activation=relu)(mp1)\n",
        "output_layer=Dense(16,softmax)(fc2)\n"
      ],
      "metadata": {
        "id": "D05lmp2h8n1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=Model(inputs=vgg_1.inputs,outputs=output_layer)"
      ],
      "metadata": {
        "id": "MlUwp8WFAPkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "ZOXvXVU7CDdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rPrVS2L9CJAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mSzygNe7CUt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mgTRZY-vXFvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MSnAIRSyXSa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5tFbBMG2Xiwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LyyNc1POXmcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "jmetVxTqXwl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}